# Introduction

Conventional CNN designs can only generate real-valued predictions and require
further postprocessing (e.g., hard thresholding or Bernoulli sampling) at test
time to obtain the final binary-valued pianorolls. This raises the following
two issues.

## Over-fragmented Notes Generated using Naïve Binarization Strategies

Naïve methods for binarizing a pianoroll at test time can easily lead to
_overly-fragmented notes_.

- For hard thresholding, the generated real-valued pianoroll has many entries
  with values close to the threshold.
- For Bernoulli sampling, it is possible to fire a note even for an entry with
  low probability due to the stochastic nature.

| Strategy                                | Result                                                                                                       |
|:---------------------------------------:|:------------------------------------------------------------------------------------------------------------:|
| raw prediction of<br>the pretrained _G_ | <img src="figs/closeup_raw.png" alt="closeup_raw" style="max-height:150px;">                                 |
| Bernoulli sampling<br>(at test time)    | <img src="figs/closeup_test_time_bernoulli.png" alt="closeup_test_time_bernoulli" style="max-height:150px;"> |
| hard thresholding<br>(at test time)     | <img src="figs/closeup_test_time_round.png" alt="closeup_test_time_round" style="max-height:150px;">         |

## Difficulties in Training the Discriminator and the Generator

The real-valued predictions generated by the generator _G_ in GAN may lead to
difficulties in training the discriminator counterpart _D_. The following figure
illustrates the decision boundaries (red dashed lines) that _D_ has to learn in
different scenarios. The decision boundaries divide the space into the _real_
class (in _blue_) and the _fake_ class (in _red_). The black and red dots
represent the real data and the fake ones generated by _G_, respectively. We can
see that the decision boundaries are easier to learn when _G_ outputs binary
values (_left_) rather than real values (_right_).

<img src="figs/theory.png" alt="theory" style="max-width:400px;">

Moreover, after passing through the first few convolutional layers of _D_, a
real-valued pianoroll generated by the _G_ may look similar to a binary-valued
pianoroll sampled from real data. As a result, _G_ does not need to “learn hard”
to generate realistic results (e.g. binary-valued ones) for it already has a
shortcut to create the so-called _adversarial examples_ to fool _D_.
